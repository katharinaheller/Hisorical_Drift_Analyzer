# Historical Drift Analyzer â€“ Ingestion Configuration
# Controls PDF parsing, language detection, metadata extraction, and chunking strategies.

global:
  # Define project root for variable expansion (${base_dir})
  # This value is automatically resolved by ConfigLoader.
  # You can also set an absolute path here if desired.
  base_dir: "${PROJECT_ROOT}"

paths:
  raw_pdfs: "${base_dir}/data/raw_pdfs"           # directory containing input PDFs
  parsed: "${base_dir}/data/processed/parsed"     # output directory for parsed JSONs
  metadata: "${base_dir}/data/processed/metadata" # output directory for extracted metadata

options:
  # --- Parsing and language setup -------------------------------------
  language: "auto"        # detect language automatically ("en" or "de" also supported)
  # You can manually set the language as "en" (English), "de" (German), or other supported languages
  pdf_parser: "fitz"      # "fitz" = PyMuPDF, "pdfplumber" = pdfplumber, "auto" = choose best local parser
  # Set PDF parsing method: 
  # "fitz" = use PyMuPDF parser
  # "pdfplumber" = use pdfplumber parser for better multi-column handling
  # "auto" = automatically choose the optimal parser based on available libraries

  # --- Parallel processing --------------------------------------------
  # Number of concurrent PDF parser processes, or "auto" for CPU-based detection
  # Set the number of parallel processes used for parsing PDFs, or "auto" for automatic detection based on available CPU cores
  parallelism: "auto"

  # --- Metadata extraction --------------------------------------------
  # List of metadata fields to extract per document
  # Available: title, authors, year, abstract, detected_language, file_size, toc
  metadata_fields:
    - title                # Extract title metadata from the document
    - authors              # Extract authors from the document metadata
    - year                 # Extract the year of publication or creation
    - detected_language    # Automatically detect the language of the document
    - file_size            # Extract the size of the PDF file in bytes
    - toc                  # Extract table of contents if available

  # --- Chunking configuration (reserved for later phases) -------------
  chunking:
    mode: "adaptive"                    # "adaptive" chooses optimal chunk sizes automatically
    # Other modes: "static" for fixed chunk size, "adaptive" for automatic chunk size based on document properties
    chunk_size: 2000                    # Used only if mode = "static", define the fixed chunk size (in tokens)
    overlap: 200                        # Overlap size in tokens (used when `enable_overlap` is true)
    enable_overlap: true                # Enable overlapping chunks between adjacent chunks
    sentence_boundary_detection: true   # Prefer splitting at sentence boundaries to maintain context
    merge_short_chunks: true            # Merge very short chunks (below min_chunk_length) to preserve context
    min_chunk_length: 400               # Discard chunks shorter than this threshold (in tokens)

  # --- Reproducibility and logging ------------------------------------
  save_intermediate: true               # Save intermediate JSONs for debugging purposes
  # Set to `true` to keep intermediate parsed/cleaned files; `false` to disable saving intermediate files
  log_level: "INFO"                     # Log verbosity level: "DEBUG", "INFO", "WARNING", "ERROR", or "CRITICAL"
  deterministic_mode: true              # Enforce reproducible output across runs (use deterministic processes like hashing)

# Additional options could include:
# - **enable_metadata_cache:** Enable caching of metadata for faster processing.
# - **exclude_empty_pages:** Whether to exclude pages with no meaningful content from processing.
